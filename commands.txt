docker build -t anirdarrazi/node-runtime:0.1 . 

docker run --rm --gpus all --ipc=host -p 8080:8080 \
  -v ~/.cache/huggingface:/root/.cache/huggingface \
  -e HUGGING_FACE_HUB_TOKEN="<your_hf_token_if_needed>" \
  -e WORKER_BASE_URL="https://radiance-api.afvagroup.workers.dev" \
  -e INTERNAL_ADMIN_TOKEN="<same as Worker secret>" \
  -e NODE_SHARED_SECRET="<same as Worker secret>" \
  -e NODE_ID="node-001" \
  -e PUBLIC_BASE_URL="https://node-001.radiance.yourdomain.com" \
  -e MODEL_ID="radiance/llama-3.1-8b-instruct-awq" \
  -e VLLM_MODEL="meta-llama/Meta-Llama-3.1-8B-Instruct" \
  -e VLLM_ARGS="--dtype auto --gpu-memory-utilization 0.90 --max-num-seqs 256" \
  -e MAX_INFLIGHT="256" \
  -e VLLM_INTERNAL_API_KEY="$(openssl rand -hex 16)" \
  radiance/node-runtime:0.1
